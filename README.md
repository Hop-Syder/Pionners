# ğŸ§± Plan Global du Projet : Transcription Automatique en Langue Fon

## Ã‰tape 0 : Objectif Final
> CrÃ©er un **systÃ¨me robuste et adaptable** qui prend une vidÃ©o/audio en entrÃ©e (en langue Fon) et produit une **transcription textuelle fidÃ¨le**, malgrÃ© les faibles ressources linguistiques disponibles.

---

## ğŸ” Ã‰tapes ClÃ©s du Pipeline

| Ã‰tape | Description | Outils RecommandÃ©s |
|------|-------------|-------------------|
| 1. Collecte de DonnÃ©es Audio | TÃ©lÃ©charger des vidÃ©os YouTube en langue Fon, extraire lâ€™audio | `yt-dlp`, `youtube-dl` |
| 2. PrÃ©traitement Audio | Nettoyage, segmentation vocale, conversion au format standard | `pydub`, `librosa`, `VAD` |
| 3. Reconnaissance Vocale (ASR) | Utilisation dâ€™un modÃ¨le ASR multilingue adaptÃ© | `Whisper (OpenAI)` |
| 4. Correction Linguistique | Post-traitement avec lexique Fon et/ou LLM lÃ©ger | `SpellChecker`, TinyLLM |
| 5. Ã‰valuation & Feedback | Comparaison avec transcriptions manuelles | WER, BLEU, CER |
| 6. Interface Utilisateur (optionnel) | Interface CLI ou Web pour faciliter lâ€™utilisation | `Streamlit`, `Gradio` |

---

# âœ… Ã‰tape par Ã‰tape : Repartons de ZÃ©ro

---

## ğŸ“¥ Ã‰tape 1 : Collecte de DonnÃ©es Audio (YouTube)

### But :
Trouver et tÃ©lÃ©charger des vidÃ©os parlÃ©es en **langue Fon** sur YouTube.

### Script Simple :

```bash
pip install yt-dlp
```

```bash
yt-dlp --extract-audio --audio-format wav \
       -o "videos/%(title)s.%(ext)s" \
       --max-downloads 20 \
       "ytsearch:language fon site:youtube.com"
```

> Ce script recherche 20 vidÃ©os contenant le mot clÃ© â€œfonâ€ ou liÃ©es Ã  la langue Fon.

---

## ğŸµ Ã‰tape 2 : Extraction et PrÃ©traitement Audio

### But :
Transformer les vidÃ©os tÃ©lÃ©chargÃ©es en fichiers audio propres.

```python
from pydub import AudioSegment
import os

def extract_audio(video_file, output_file):
    audio = AudioSegment.from_file(video_file)
    audio.export(output_file, format="wav")

video_dir = "videos/"
audio_dir = "audios/"
os.makedirs(audio_dir, exist_ok=True)

for file in os.listdir(video_dir):
    if file.endswith(".mp4"):
        input_path = os.path.join(video_dir, file)
        output_path = os.path.join(audio_dir, file.replace(".mp4", ".wav"))
        extract_audio(input_path, output_path)
```

---

## ğŸ—£ï¸ Ã‰tape 3 : Transcription via Whisper (ASR)

### But :
Utiliser Whisper pour gÃ©nÃ©rer une transcription brute.

```bash
pip install openai-whisper
```

```python
import whisper

model = whisper.load_model("large")  # Vous pouvez aussi utiliser "medium" ou "small"

def transcribe_audio(audio_file):
    result = model.transcribe(audio_file, language="fr")
    return result["text"]
```

> Note : Nous utilisons `"fr"` comme langue car le modÃ¨le ne reconnaÃ®t pas nativement le **Fon**.

---

## ğŸ“š Ã‰tape 4 : Correction Linguistique en Langue Fon

### But :
AmÃ©liorer la transcription grÃ¢ce Ã  un correcteur basÃ© sur un **lexique Fon**.

#### Solution 1 : Lexique + Spellchecker

```bash
pip install spellchecker
```

CrÃ©ez un fichier texte (`fon_dict.txt`) contenant les mots Fon connus, un par ligne.

```python
from spellchecker import SpellChecker

spell = SpellChecker(language=None, local_dictionary='fon_dict.txt')

def correct_transcript(text):
    words = text.split()
    corrected_words = [spell.correction(word) for word in words]
    return " ".join(corrected_words)
```

#### Solution 2 : ModÃ¨le de Langue ou LLM LÃ©ger (TinyLLM / Phi-3)

Fine-tunez un petit modÃ¨le sur un corpus Fon disponible (ex : [African Language Resources](https://github.com/topics/african-languages)) ou utilisez un prompt pour corriger la syntaxe :

```python
def prompt_corrector(transcribed_text):
    prompt = f"""
Corrige cette transcription en respectant l'orthographe et la grammaire en langue Fon :
{transcribed_text}
"""
    # Ã€ connecter Ã  un LLM local ou API
    corrected_text = call_local_llm(prompt)  # Exemple fictif
    return corrected_text
```

---

## ğŸ“Š Ã‰tape 5 : Ã‰valuation Quantitative

### But :
Mesurer la qualitÃ© des transcriptions.

```bash
pip install jiwer
```

```python
from jiwer import wer, cer

reference = "Transcription correcte en langue Fon."
hypothesis = "Transcription bruitee en lang Fon."

print("WER:", wer(reference, hypothesis))
print("CER:", cer(reference, hypothesis))
```

---

## ğŸ–¥ï¸ Ã‰tape 6 : Interface Utilisateur (Facultatif mais utile)

### But :
CrÃ©er une interface simple pour tester facilement vos transcriptions.

```bash
pip install streamlit
```

```python
import streamlit as st
import os

st.title("Transcripteur Automatique en Langue Fon")

uploaded_file = st.file_uploader("TÃ©lÃ©chargez une vidÃ©o ou un fichier audio", type=["mp4", "wav"])

if uploaded_file:
    with open(os.path.join("audios", uploaded_file.name), "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.success("Fichier tÃ©lÃ©chargÃ© !")
    
    # Appel Ã  la fonction de transcription
    transcript = transcribe_audio(f"audios/{uploaded_file.name}")
    st.subheader("Transcription brute")
    st.write(transcript)
    
    corrected = correct_transcript(transcript)
    st.subheader("Transcription corrigÃ©e")
    st.write(corrected)
```

Lancez avec :

```bash
streamlit run app.py
```

---

# ğŸ§  RÃ©sumÃ© du Workflow Final

```
YouTube VidÃ©o â†’ Extraction Audio â†’ Whisper â†’ Correction Orthographique â†’ Transcription Finale
```

---

# ğŸ“¦ Structure de Dossier ProposÃ©e

```
projet-fon/
â”œâ”€â”€ videos/
â”‚   â””â”€â”€ video1.mp4 ...
â”œâ”€â”€ audios/
â”‚   â””â”€â”€ audio1.wav ...
â”œâ”€â”€ transcripts/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ corrected/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ whisper/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ audio_utils.py
â”‚   â”œâ”€â”€ asr_pipeline.py
â”‚   â””â”€â”€ correction.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â””â”€â”€ samples/
â””â”€â”€ app.py
```

---

